{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f903f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ..\\config.json\n",
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: AML-Clinical-Readmission\n",
      "Using environment: azureml:clinical-prep-env:2\n",
      "Submitting E2E Clinical Readmission Pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading src (0.02 MBs): 100%|##########| 19618/19618 [00:01<00:00, 17868.75it/s]\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline submitted. Track it in Azure ML Studio:\n",
      "https://ml.azure.com/runs/silver_ticket_2pnzx6mvf9?wsid=/subscriptions/3aeb63fe-f831-47f0-8175-3732f2efd2a1/resourcegroups/RG-Clinical-Readmission/workspaces/AML-Clinical-Readmission&tid=deb5bf9d-8bb0-4783-8f54-42a424392492\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# NOTEBOOK: 4_pipeline_build.ipynb\n",
    "# GOAL: Build an end-to-end Azure ML pipeline:\n",
    "#   1) Data prep (split MLTable into train/test folders)\n",
    "#   2) Train XGBoost model with MLflow autologging\n",
    "#\n",
    "# ASSUMPTIONS:\n",
    "#   - Folder structure:\n",
    "#         project-root/\n",
    "#           src/\n",
    "#             prep.py\n",
    "#             train.py\n",
    "#             conda.yml\n",
    "#           notebooks/\n",
    "#             4_pipeline_build.ipynb\n",
    "#   - Data asset \"diabetes-clinical-enriched-130us:<version>\" exists (MLTable)\n",
    "#   - Compute cluster \"clinical-cluster-cpu\" exists\n",
    "#   - Environment \"clinical-prep-env:2\" exists and includes:\n",
    "#         python=3.8, pandas, scikit-learn, xgboost, azureml-mlflow\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "from azure.ai.ml import MLClient, dsl, Input, Output, command\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. CONNECT TO WORKSPACE (silent auth first, then interactive)\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Probe token to see if silent auth works\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception:\n",
    "    print(\"DefaultAzureCredential failed; falling back to InteractiveBrowserCredential...\")\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# config.json should be one level up from this notebook (../config.json)\n",
    "ml_client = MLClient.from_config(credential=credential, path=\"../config.json\")\n",
    "print(f\"Connected to workspace: {ml_client.workspace_name}\")\n",
    "\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. FIXED ENVIRONMENT STRING\n",
    "# ---------------------------------------------------------\n",
    "# Name  : clinical-prep-env\n",
    "# Version: 2\n",
    "ENV_STR = \"azureml:clinical-prep-env:2\"\n",
    "print(f\"Using environment: {ENV_STR}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. DEFINE PIPELINE\n",
    "# ---------------------------------------------------------\n",
    "@dsl.pipeline(\n",
    "    description=\"E2E Clinical Readmission Pipeline (Enrich + Prep + Train)\"\n",
    ")\n",
    "def clinical_readmission_pipeline(\n",
    "    raw_data: Input(type=\"uri_file\"),  # Pipeline input: raw CSV data asset\n",
    "):\n",
    "    # -------------------------------------------------\n",
    "    # STEP 1: ICD ENRICHMENT\n",
    "    #   - Input: raw diabetic_data.csv (uri_file)\n",
    "    #   - Output: folder with diabetes_clinical_enriched.csv\n",
    "    # -------------------------------------------------\n",
    "    enrich_node = command(\n",
    "        name=\"icd_enrich\",\n",
    "        display_name=\"ICD-9 to ICD-10 Enrichment\",\n",
    "        description=\"Enrich raw US diabetic data with ICD-10 style grouping and HbA1c risk flag.\",\n",
    "        inputs={\n",
    "            \"raw_data\": Input(type=\"uri_file\")\n",
    "        },\n",
    "        outputs={\n",
    "            \"enriched_data\": Output(type=\"uri_folder\")\n",
    "        },\n",
    "        code=\"../src\",  # where icd_enrich.py lives\n",
    "        command=(\n",
    "            \"python icd_enrich.py \"\n",
    "            \"--raw_data ${{inputs.raw_data}} \"\n",
    "            \"--output_dir ${{outputs.enriched_data}}\"\n",
    "        ),\n",
    "        environment=ENV_STR,\n",
    "    )(\n",
    "        raw_data=raw_data\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # STEP 2: DATA PREP\n",
    "    #   - Input: enriched data folder (from enrich_node)\n",
    "    #   - Output: two uri_folder outputs with train.csv and test.csv\n",
    "    # -------------------------------------------------\n",
    "    prep_node = command(\n",
    "        name=\"prep_data\",\n",
    "        display_name=\"Data Prep\",\n",
    "        description=\"Splits enriched clinical data into train and test CSVs\",\n",
    "        inputs={\n",
    "            \"data\": Input(type=\"uri_folder\")\n",
    "        },\n",
    "        outputs={\n",
    "            \"train_data\": Output(type=\"uri_folder\"),\n",
    "            \"test_data\": Output(type=\"uri_folder\"),\n",
    "        },\n",
    "        code=\"../src\",\n",
    "        command=(\n",
    "            \"python prep.py \"\n",
    "            \"--data ${{inputs.data}} \"\n",
    "            \"--train_data ${{outputs.train_data}} \"\n",
    "            \"--test_data ${{outputs.test_data}}\"\n",
    "        ),\n",
    "        environment=ENV_STR,\n",
    "    )(\n",
    "        data=enrich_node.outputs.enriched_data\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # STEP 3: TRAINING\n",
    "    #   - Inputs: the two folders from prep_node (train_data, test_data)\n",
    "    #   - Output: model folder (uri_folder) with model.json\n",
    "    #   - train.py uses MLflow autolog + azureml-mlflow\n",
    "    # -------------------------------------------------\n",
    "    train_node = command(\n",
    "        name=\"train_model\",\n",
    "        display_name=\"Train XGBoost\",\n",
    "        description=\"Trains XGBoost model to predict 30-day readmission\",\n",
    "        inputs={\n",
    "            \"train_data\": Input(type=\"uri_folder\"),\n",
    "            \"test_data\": Input(type=\"uri_folder\"),\n",
    "        },\n",
    "        outputs={\n",
    "            # Folder where train.py saves the trained model (e.g., model.json)\n",
    "            \"model_output\": Output(type=\"uri_folder\")\n",
    "        },\n",
    "        code=\"../src\",\n",
    "        command=(\n",
    "            \"python train.py \"\n",
    "            \"--train_data ${{inputs.train_data}} \"\n",
    "            \"--test_data ${{inputs.test_data}} \"\n",
    "            \"--model_output ${{outputs.model_output}}\"\n",
    "        ),\n",
    "        environment=ENV_STR,\n",
    "    )(\n",
    "        train_data=prep_node.outputs.train_data,\n",
    "        test_data=prep_node.outputs.test_data,\n",
    "    )\n",
    "\n",
    "    # Pipeline return: expose the trained model as the pipeline's output\n",
    "    return {\"trained_model\": train_node.outputs.model_output}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. INSTANTIATE AND SUBMIT PIPELINE JOB\n",
    "# ---------------------------------------------------------\n",
    "# Raw data asset (uri_file) you registered for diabetic_data.csv\n",
    "raw_data_asset_name = \"diabetic-data-raw-130us\"   # raw dataset name\n",
    "raw_version = \"1\"                       # first version\n",
    "\n",
    "pipeline_job = clinical_readmission_pipeline(\n",
    "    raw_data=Input(\n",
    "        type=\"uri_file\",\n",
    "        path=f\"azureml:{raw_data_asset_name}:{raw_version}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Use the same compute you used for standalone jobs\n",
    "pipeline_job.settings.default_compute = \"clinical-cluster-cpu\"\n",
    "\n",
    "# Optional: give the pipeline run a friendly display name\n",
    "pipeline_job.display_name = \"Clinical_Readmission_E2E_Full_Manual\"\n",
    "\n",
    "print(\"Submitting E2E Clinical Readmission Pipeline...\")\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job,\n",
    "    experiment_name=\"Clinical_Readmission_Pipeline_E2E\",\n",
    ")\n",
    "\n",
    "print(\"Pipeline submitted. Track it in Azure ML Studio:\")\n",
    "print(returned_job.studio_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
